{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d4c577-6082-4a0d-be47-1d102055bff1",
   "metadata": {
    "id": "80d4c577-6082-4a0d-be47-1d102055bff1"
   },
   "source": [
    "# COMPSCI 714 - Lectutorial 2 - Training and evaluating a DNN with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53606c-e892-4321-bf19-f4364dac1275",
   "metadata": {
    "id": "cf53606c-e892-4321-bf19-f4364dac1275"
   },
   "source": [
    "## Coding time 1 - PyTorch basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a43ef-8e18-44cb-b6c8-bb5494df6a9b",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1741839396921,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "1c2a43ef-8e18-44cb-b6c8-bb5494df6a9b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbfbb66-5fb2-4d4c-80f2-94c4672ee147",
   "metadata": {
    "id": "cfbfbb66-5fb2-4d4c-80f2-94c4672ee147"
   },
   "source": [
    "### Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7143a9-2596-41ab-a44a-58a10c85a99b",
   "metadata": {
    "id": "1a7143a9-2596-41ab-a44a-58a10c85a99b"
   },
   "source": [
    "The core data structure used in PyTorch is the **tensor**. They are very similars to arrays and matrices (e.g., NumPy array) and can be used to store data as a multidimentional array with a data type.\n",
    "\n",
    "The main difference with Numpy arrays is that Pytorch tensors supports two main additional features:\n",
    "- They can run on GPUs, while NumPy arrays are designed for CPU-based computations only and do not have built-in GPU support.\n",
    "- They support auto-differentiation (i.e., PyTorch captures information about operations applied to the tensor and can use it to calculate gradients automatically with *Autograd*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747d4ed-5c8e-43ec-a145-72043a676473",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741839396927,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "7747d4ed-5c8e-43ec-a145-72043a676473",
    "outputId": "a30e84e8-4879-4577-a88f-f7eefe492658"
   },
   "outputs": [],
   "source": [
    "X = torch.tensor([[1.0, 4.0, 7.0, 9.0], [2.0, 3.0, 6.0, 8.0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba9588-e1c6-4b34-b0dd-7f03a94e19ac",
   "metadata": {
    "id": "7aba9588-e1c6-4b34-b0dd-7f03a94e19ac"
   },
   "source": [
    "Display the shape and data type of the tensor `X` (similar than with a NumPy array with the `shape` and `dtype` fields)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99091121-9298-49fe-98be-aea1c0b5fafd",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741839396930,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "99091121-9298-49fe-98be-aea1c0b5fafd"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5d922-e5d5-4b53-9350-f7a6986edd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897421c9-47a0-4448-8c2f-4ece271f34ab",
   "metadata": {
    "id": "897421c9-47a0-4448-8c2f-4ece271f34ab"
   },
   "source": [
    "Try to index the tensor, e.g., display\n",
    "- the third value of the first row, and\n",
    "- the last values of the both rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c600adb-01e7-4f2b-845e-bdecdd5c3df6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1741839396936,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "2c600adb-01e7-4f2b-845e-bdecdd5c3df6",
    "outputId": "13e516d7-b7e4-49c4-c6ba-cb54b9a31f56"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a4d91-d273-4c30-9e60-0195d2671bee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741839396944,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "cc0a4d91-d273-4c30-9e60-0195d2671bee",
    "outputId": "c06ad779-21ea-40d7-dc77-a236de9342cf"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c278c-f87c-4d8b-ba2b-c032ef9131b0",
   "metadata": {
    "id": "c36c278c-f87c-4d8b-ba2b-c032ef9131b0"
   },
   "source": [
    "You can perform operations on tensors very similarly as on NumPy arrays. \\\n",
    "Try to run the few following operations and comment on what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44c14f-4e0b-4b0e-9ff8-1b857a2b2eca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1741839397071,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "eb44c14f-4e0b-4b0e-9ff8-1b857a2b2eca",
    "outputId": "4918c500-175f-4cce-a4ad-affbb64169b6"
   },
   "outputs": [],
   "source": [
    "8 * (X + 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be601676-0714-4e53-ab76-42323160cdf3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741839397075,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "be601676-0714-4e53-ab76-42323160cdf3",
    "outputId": "8421e872-a32e-4271-ea45-1a0e9b057ee1"
   },
   "outputs": [],
   "source": [
    "X.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95201990-204a-4b57-bde4-c159d3d42e00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1741839397096,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "95201990-204a-4b57-bde4-c159d3d42e00",
    "outputId": "4c0173e3-311d-4eb4-87fc-1be4918ae981"
   },
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237aa69-665f-4e8a-b57d-37968fe9c825",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741839397097,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "d237aa69-665f-4e8a-b57d-37968fe9c825",
    "outputId": "f25a4c2c-c5f5-4c17-fa62-46390f83b269"
   },
   "outputs": [],
   "source": [
    "X.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed4eb9-a886-489e-8c70-b5ae473bf7ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741839397098,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "16ed4eb9-a886-489e-8c70-b5ae473bf7ce",
    "outputId": "1f683d3a-5e18-4fb2-a280-22ef0d88bf34"
   },
   "outputs": [],
   "source": [
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2d416-d1b2-4996-a352-3181546e0cba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741839397099,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "afa2d416-d1b2-4996-a352-3181546e0cba",
    "outputId": "c7e65bdf-a3c4-4cb9-ac09-cd9cf604afb0"
   },
   "outputs": [],
   "source": [
    "X @ X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283fa30-b401-44e0-9912-9c911fba9ff7",
   "metadata": {
    "id": "e283fa30-b401-44e0-9912-9c911fba9ff7"
   },
   "source": [
    "You can convert a tensor to a NumPy array, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af2666-4d7a-41c9-828c-f3ecae14aa1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741839397099,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "f4af2666-4d7a-41c9-828c-f3ecae14aa1c",
    "outputId": "94eb55d0-81bc-44dd-8781-ebff2c66a735"
   },
   "outputs": [],
   "source": [
    "X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f79226-3948-43b5-83d3-cccc023ccf9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1741839397129,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "e8f79226-3948-43b5-83d3-cccc023ccf9c",
    "outputId": "98815c9c-69bd-44e2-ca36-9f414c76ef92"
   },
   "outputs": [],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0566d-8564-45fc-94a6-fb6559b2e1e0",
   "metadata": {
    "id": "b6d0566d-8564-45fc-94a6-fb6559b2e1e0"
   },
   "source": [
    "Or if you want the data precision of the tensor to be converted to 32-bits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd54f65-0cd0-476b-8480-05e5e7874087",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1741839397130,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "4dd54f65-0cd0-476b-8480-05e5e7874087",
    "outputId": "d0a268a1-ae0d-465d-f102-4e056edadafa"
   },
   "outputs": [],
   "source": [
    "torch.FloatTensor(np.array([[1., 4., 7.], [2., 3., 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6569553c-b72c-4815-81a0-5cac2e6a8f7a",
   "metadata": {
    "id": "6569553c-b72c-4815-81a0-5cac2e6a8f7a"
   },
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cf72c-2ef3-496b-b1e0-97f8f510e6f0",
   "metadata": {
    "id": "ab5cf72c-2ef3-496b-b1e0-97f8f510e6f0"
   },
   "source": [
    "PyTorch comes with an implementation of auto-differentiation called *Autograd* (Automated gradients). It can be used to compute the derivative of a function, i.e., its gradient. For a enable *Autograd* to be performed on a tensor, you have to set `requires_grad=True` when creating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc85d0c-fa5e-4b54-9c5c-bc2c6d873970",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741839397130,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "bcc85d0c-fa5e-4b54-9c5c-bc2c6d873970",
    "outputId": "069ff971-8863-4a8b-88a3-f2ae95e47e17"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93433bef-0d46-4048-8294-67d2547f6e8c",
   "metadata": {
    "id": "93433bef-0d46-4048-8294-67d2547f6e8c"
   },
   "source": [
    "Let's then create a function performing a computation on tensor `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f0126-e649-4f9a-8fd9-de235536ee11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741839397131,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "8c5f0126-e649-4f9a-8fd9-de235536ee11",
    "outputId": "8f0f3ee1-ea4e-46e3-ff4f-23cf8d7cbf82"
   },
   "outputs": [],
   "source": [
    "f = x ** 2\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b4932-8499-448d-b9ff-72744f255d46",
   "metadata": {
    "id": "e99b4932-8499-448d-b9ff-72744f255d46"
   },
   "source": [
    "Notice that `f` is also a tensor, carrying the fucntion `grad_fn=<PowBackward0>`. It is the function that would be used if you ecide to backpropagate the gradients through the operation performed by `f` (** is the power operator, hence the name `PowBackward0`).\n",
    "\n",
    "Let's now backpropagate the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3710de0-b522-4973-b7c3-142f97c9e45a",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741839397131,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "b3710de0-b522-4973-b7c3-142f97c9e45a"
   },
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5428e31b-7802-4624-8693-d0e503e55ddf",
   "metadata": {
    "id": "5428e31b-7802-4624-8693-d0e503e55ddf"
   },
   "source": [
    "This backpropagates the gradient from `f` to `x`. This is quite straighforward here, but imagine this applied to a full DNN. The gradient would be backpropagated from the outputs to the inputs, through all the `grad_fn` registered during the forward pass.\n",
    "\n",
    "Let's now have a look at the gradient value associated with `x`, i.e., the value of the derivative of `f` with respect to `x` Does this value makes sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be388adf-5228-40da-9e6c-b6873b4456f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741839397138,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "be388adf-5228-40da-9e6c-b6873b4456f6",
    "outputId": "945f097b-5c82-4ccc-e30e-fc7b686970de"
   },
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c95223-7786-4c51-9806-805b21e3daf0",
   "metadata": {
    "id": "16c95223-7786-4c51-9806-805b21e3daf0"
   },
   "source": [
    "### Hardware acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249c9db-d789-4557-bdae-edb9ffa5a1ae",
   "metadata": {
    "id": "9249c9db-d789-4557-bdae-edb9ffa5a1ae"
   },
   "source": [
    "CUDA-enabled NVIDIA GPU and Apple's MPS are directly supported by PyTorch. You can check for them and else fall back on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617b468-e4d5-454a-9512-fd44ce36c196",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741839397139,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "a617b468-e4d5-454a-9512-fd44ce36c196"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wRxfedDdD7zP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741839397140,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "wRxfedDdD7zP",
    "outputId": "c2b81074-d870-45fe-e012-1b21781c45d9"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32cd3a-2073-4bc7-b4bd-bee71324c4e8",
   "metadata": {
    "id": "0f32cd3a-2073-4bc7-b4bd-bee71324c4e8"
   },
   "source": [
    "To perform computations with tensors on a GPU, you need to move your tensors to the GPU device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabec78-28d6-4c60-9361-4b90512d17b5",
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1741839397403,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "1fabec78-28d6-4c60-9361-4b90512d17b5"
   },
   "outputs": [],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "M = M.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea60f22-30c2-44b6-9d6d-6baed78c49fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1741839397412,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "2ea60f22-30c2-44b6-9d6d-6baed78c49fc",
    "outputId": "0b12c0b8-3fb7-474e-b66f-bfbd02755a9c"
   },
   "outputs": [],
   "source": [
    "M.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c579d-c9cd-4e16-842f-a444c3d8b380",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741839397412,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "2e7c579d-c9cd-4e16-842f-a444c3d8b380"
   },
   "outputs": [],
   "source": [
    "M = torch.tensor([[2., 4., 6.], [8., 6., 4.]], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b59de0-940a-4430-b2b6-a98e22d3cb10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741839397413,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "40b59de0-940a-4430-b2b6-a98e22d3cb10",
    "outputId": "a71a41ef-4644-4886-cc46-dae2e18b341f"
   },
   "outputs": [],
   "source": [
    "M.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c5701-8552-4e53-844c-37d585a2d7ba",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741839397414,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "be7c5701-8552-4e53-844c-37d585a2d7ba"
   },
   "outputs": [],
   "source": [
    "M = torch.rand((1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75fb13-d06f-4b5a-9c9e-4e6abe92dc68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2859,
     "status": "ok",
     "timestamp": 1741839400270,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "8a75fb13-d06f-4b5a-9c9e-4e6abe92dc68",
    "outputId": "61bd9c7f-8932-4693-b1a6-7fcbd02c5fa9"
   },
   "outputs": [],
   "source": [
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a116b63-69eb-4a6e-a9bb-630225b32d94",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1741839400313,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "0a116b63-69eb-4a6e-a9bb-630225b32d94"
   },
   "outputs": [],
   "source": [
    "M = torch.rand((1000, 1000), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226d556-08aa-432d-ae3f-e0811fa7acd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4298,
     "status": "ok",
     "timestamp": 1741839404612,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "1226d556-08aa-432d-ae3f-e0811fa7acd0",
    "outputId": "f1cee118-1737-412c-c661-688943f35f7c"
   },
   "outputs": [],
   "source": [
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87wwLZasEau8",
   "metadata": {
    "id": "87wwLZasEau8"
   },
   "source": [
    "How much faster is this matrix multiplication being computed on GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4108bb6-60a1-4569-8fac-551d94d606fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W-lDl2z6EzEl",
   "metadata": {
    "id": "W-lDl2z6EzEl"
   },
   "source": [
    "## Coding time 2: Training a simple DNN for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ll1DYwtbJNK3",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741835475872,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "Ll1DYwtbJNK3"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F_Zh2EXDJe3-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4180,
     "status": "ok",
     "timestamp": 1741835641517,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "F_Zh2EXDJe3-",
    "outputId": "a0d30171-d080-4b41-9d95-ab6103eb8880"
   },
   "outputs": [],
   "source": [
    "%pip install torchmetrics\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tb45TMDjI3qk",
   "metadata": {
    "id": "tb45TMDjI3qk"
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PVWGz5Lyjayk",
   "metadata": {
    "id": "PVWGz5Lyjayk"
   },
   "source": [
    "#### Loading the dataset\n",
    "\n",
    "Let's first load the california housing dataset from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cNAtveGOFB8F",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741835385730,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "cNAtveGOFB8F"
   },
   "outputs": [],
   "source": [
    "housing_dataset = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fKuqBU7hKoyd",
   "metadata": {
    "id": "fKuqBU7hKoyd"
   },
   "source": [
    "Run the next cell to see what data format is the dataset loaded as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jwNlzbxpKym8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741830536674,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "jwNlzbxpKym8",
    "outputId": "91c604d2-adad-4a85-d883-306fdc1db0ed"
   },
   "outputs": [],
   "source": [
    "type(housing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fj1nLnxsLMBl",
   "metadata": {
    "id": "fj1nLnxsLMBl"
   },
   "source": [
    "What is the shape of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jVFPGgi6KXP9",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741830290672,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "jVFPGgi6KXP9"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aRNRakxWKS71",
   "metadata": {
    "id": "aRNRakxWKS71"
   },
   "source": [
    "First, let's divide it into train/validation/test sets with a 60%/20%/20% ratio.\n",
    "\n",
    "The next line of code splits the data into train/test sets with a 80%/20% ratio. Extend the code to create the validation set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ikesNYURJzCd",
   "metadata": {
    "id": "ikesNYURJzCd"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing_dataset.data, housing_dataset.target, test_size=0.2)\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R19jzIlxMgKN",
   "metadata": {
    "id": "R19jzIlxMgKN"
   },
   "source": [
    "How many samples are there in each set?\n",
    "\n",
    "What is the type of data structure used to store the sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qAWepEylMkPk",
   "metadata": {
    "id": "qAWepEylMkPk"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tINmP5wCMrUN",
   "metadata": {
    "id": "tINmP5wCMrUN"
   },
   "source": [
    "As we saw before, PyTorch works with tensors. We need to convert the sets and associated targets to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kGwWZxQINEON",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741835394741,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "kGwWZxQINEON"
   },
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_valid = torch.FloatTensor(y_valid)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rMJCIaEUNKYb",
   "metadata": {
    "id": "rMJCIaEUNKYb"
   },
   "source": [
    "Next, we will do a quick touch of pre-processing by standardising the values of the attributes. We can do it manually this time, by computing the mean and standard deviation for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XHdNTKklNcy8",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741835396527,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "XHdNTKklNcy8"
   },
   "outputs": [],
   "source": [
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train = (X_train - means) / stds\n",
    "X_valid = (X_valid - means) / stds\n",
    "X_test = (X_test - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6rydKq8nNj09",
   "metadata": {
    "id": "6rydKq8nNj09"
   },
   "source": [
    "What are the shapes of `y_train`, `y_valid` and `y_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1yqMNk1HNiYt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741831078758,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "1yqMNk1HNiYt",
    "outputId": "d97bbb48-76af-4556-ccad-6da3d3091a2a"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pTSoWlRXOSBF",
   "metadata": {
    "id": "pTSoWlRXOSBF"
   },
   "source": [
    "These are 1D tensors, however, PyTorch models generally expects 2D tensors. 1D tensors might be treated differently from a 2D tensors when performing some operations like matrix multiplication.\n",
    "\n",
    "Therefore, we need to reshape our target tensors to 2D tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffKWS27N4j1",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741835399214,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "8ffKWS27N4j1"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_valid = y_valid.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UPUDbiQlPXcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741831371928,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "UPUDbiQlPXcd",
    "outputId": "ad08b106-2cae-4c80-e6ea-6d5272fc07df"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seK0QSEGRDoV",
   "metadata": {
    "id": "seK0QSEGRDoV"
   },
   "source": [
    "#### Declaring the model\n",
    "\n",
    "Next, let's create our first multilayer neural network! The easiest way is to use the PyTorch `nn.Sequential` module. It allows to create a stack of layers.\n",
    "\n",
    "The following cell defines a neural network with:\n",
    "- 2 hidden layers, the first one with 50 neurons and the second one with 40 neurons. Both use the ReLU activation function (we will cover it next week).\n",
    "- 1 output layer.\n",
    "\n",
    "Note that we declared all the layers as full-connected layers, also called dense layers, with the `nn.Linear` module. To create a `Linear` layer, we need to pass the shape of the parameter matrix as argument. This shape corresponds to the layers's $number\\ of\\ inputs \\times number\\ of\\ outputs$.\n",
    "\n",
    "What should be the values of assigned to the variables `n_attributes` and `n_outputs`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sVo8Mj8xUUft",
   "metadata": {
    "id": "sVo8Mj8xUUft"
   },
   "outputs": [],
   "source": [
    "n_attributes = # TODO\n",
    "n_outputs = # TODO\n",
    "my_model = nn.Sequential(\n",
    "nn.Linear(n_attributes, 50),\n",
    "nn.ReLU(),\n",
    "nn.Linear(50, 40),\n",
    "nn.ReLU(),\n",
    "nn.Linear(40, n_outputs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZYVAkXX-wwaj",
   "metadata": {
    "id": "ZYVAkXX-wwaj"
   },
   "source": [
    "We can wrap this in a function as we might need to reset our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P0NS92yHxF9y",
   "metadata": {
    "id": "P0NS92yHxF9y"
   },
   "outputs": [],
   "source": [
    "def set_model():\n",
    "  # TODO\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wjg3ZpgKVrF1",
   "metadata": {
    "id": "wjg3ZpgKVrF1"
   },
   "source": [
    "#### Training the model\n",
    "\n",
    "Next, we need to set:\n",
    "- the optimiser we want to use to train the model (let's use SGD),\n",
    "- the loss function (let's use MSE),\n",
    "- the learning rate (let's start at 0.1),\n",
    "- the number of epochs (let's set it to 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Ydsa4DkVqTN",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1741835536590,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "2Ydsa4DkVqTN"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7TDcipkpYQ08",
   "metadata": {
    "id": "7TDcipkpYQ08"
   },
   "source": [
    "Finally, let's define a simple training loop.\n",
    "\n",
    "If you have a look at hos to do this with TensorFlow, you will see that the module you can use to create a model has already a pre-defined method to train (*fit*) the model. With PyTorch, you have to create the training loop yourself. It can be seen as more tedious, but on the positive side, it gives you more control as well. And it is great to break down and understand each step of the training!\n",
    "\n",
    "For better reusability, let's create a function `train` in which we will build our training loop.\n",
    "\n",
    "Complete the training loop in the function below, by including the following intructions in the correct order:\n",
    "- `loss.backward()`: calculates the gradient of the loss with respect to the model's parameters\n",
    "- `optimizer.step()`: take a step of optimisation\n",
    "- `y_pred = model(X_train)`: performs a forward pass\n",
    "- `optimizer.zero_grad()`: resets the gradients of all tensors\n",
    "- `loss = loss_fn(y_pred, y_train)`: calculates the loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "khSMHR1La6mU",
   "metadata": {
    "id": "khSMHR1La6mU"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, X_train, y_train, n_epochs):\n",
    "  for epoch in range(n_epochs):\n",
    "    # Intruction 1\n",
    "    # Intruction 2\n",
    "    # Intruction 3\n",
    "    # Intruction 4\n",
    "    # Intruction 5\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VYfO2wGNcZy3",
   "metadata": {
    "id": "VYfO2wGNcZy3"
   },
   "source": [
    "Now, we are ready to train our model!\n",
    "Run the following function call to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iVqGPHz7chtl",
   "metadata": {
    "id": "iVqGPHz7chtl"
   },
   "outputs": [],
   "source": [
    "train(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QNKu3Zffc0-0",
   "metadata": {
    "id": "QNKu3Zffc0-0"
   },
   "source": [
    "Modify your training function to return a list of the loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EE3DEUi1gQQ6",
   "metadata": {
    "id": "EE3DEUi1gQQ6"
   },
   "outputs": [],
   "source": [
    "def train_v2(model, optimizer, loss_fn, X_train, y_train, n_epochs):\n",
    "  losses = []\n",
    "  for epoch in range(n_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7U5Jvh8UdRFj",
   "metadata": {
    "id": "7U5Jvh8UdRFj"
   },
   "source": [
    "Train the model again and plot the loss after training.\n",
    "\n",
    "**Warning**: The training of your model will resume where it stopped. If you want to start training from stratch again, you need to reset the model parameters by re-run the cells where you declared the model and optimiser first, or using the `set_model()` function we declared to that end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xoZFzlOdfw6M",
   "metadata": {
    "id": "xoZFzlOdfw6M"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OQEFCuHce4e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1741835573586,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "OQEFCuHce4e0",
    "outputId": "487617d2-6ed4-4358-bb59-8e5955af6e0a"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_zUjqvijgL8b",
   "metadata": {
    "id": "_zUjqvijgL8b"
   },
   "source": [
    "#### Implementing Mini-batch GD\n",
    "\n",
    "What type of gradient descent have you used so far?\n",
    "\n",
    "Let's now try to implement Mini-batch gradient descent.\n",
    "\n",
    "To do so, we need to use the `DataLoader` class which facilitate the loading of batches of data. To be able to use a `DataLoader`, we first need to wrap our dataset as a `TensorDataset` object (this provide the correct API to the `DataLoader` class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o0BvqttegLjD",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741838827009,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "o0BvqttegLjD"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # Creates a DataLoader for loading batches of 32 random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w3FpxQi8tb8r",
   "metadata": {
    "id": "w3FpxQi8tb8r"
   },
   "source": [
    "Let's also use the GPU to train the model this time. To do so, we need to move the model tensors to GPU with the following instruction.\n",
    "\n",
    "**Warning**: Do not forget to reinitialise your model parameter first by re-running the cell where you defined it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXhbZnSktnXs",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741842675909,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "xXhbZnSktnXs"
   },
   "outputs": [],
   "source": [
    "model = set_model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X-wWeuDRuHU0",
   "metadata": {
    "id": "X-wWeuDRuHU0"
   },
   "source": [
    "Let's now update our training loop to:\n",
    "- Calculate the gradient update over a batch of data and not the full dataset.\n",
    "- Use the GPU to perform the training.\n",
    "\n",
    "Look at the lines with the #NEW tag and try to understand wht changed compared to the previous training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pyIHNubJkBCU",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741842666023,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "pyIHNubJkBCU"
   },
   "outputs": [],
   "source": [
    "def train_v3(model, optimizer, loss_fn, train_loader, n_epochs):\n",
    "    losses = []\n",
    "    model.train() # Puts the model in training mode, will be useful later on when we use other types of layers\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0. # NEW\n",
    "        for X_batch, y_batch in train_loader: # NEW\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device) # NEW\n",
    "            y_pred = model(X_batch) # NEW\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            epoch_loss += loss.item() # NEW\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        mean_epoch_loss = epoch_loss / len(train_loader) # NEW\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_epoch_loss:.4f}\")\n",
    "        losses.append(mean_epoch_loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pVnA9HP1z2XD",
   "metadata": {
    "id": "pVnA9HP1z2XD"
   },
   "source": [
    "You can now train the model with the new training loop.\n",
    "\n",
    "You can try to lower the learning rate by a factor 10 if the training does not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usQgfRr70Jma",
   "metadata": {
    "id": "usQgfRr70Jma"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ylGmy66_zuZZ",
   "metadata": {
    "id": "ylGmy66_zuZZ"
   },
   "source": [
    "We reached a lower loss than before, but each epoch took more time.\n",
    "\n",
    "The lower loss can be explained by the fact that mini-batch GD introduces some stochatiscity in the optimisation process (i.e., it can help avoid local minima).\n",
    "\n",
    "The higher time per update is explained by the fact that mini-batch GD makes several gradient update per epoch, while batch GD does only one. However, we reached a lower loss in with mini-batch GD in much less epochs than with batch GD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7y2SDSUF_YHt",
   "metadata": {
    "id": "7y2SDSUF_YHt"
   },
   "source": [
    "## Coding time 3: Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaPKfQCvolz",
   "metadata": {
    "id": "8aaPKfQCvolz"
   },
   "source": [
    "### Validation loss\n",
    "\n",
    "It is usually good to also evaluate the model's loss on the validation set after each epoch, e.g., to monitor for overfitting.\n",
    "\n",
    "Let's update our train function to include this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rSYaVM8w2HWr",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741846156669,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "rSYaVM8w2HWr"
   },
   "outputs": [],
   "source": [
    "def train_v4(model, optimizer, loss_fn, train_loader, valid_loader, n_epochs):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        #Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            y_train_pred = model(X_train_batch)\n",
    "            train_loss = loss_fn(y_train_pred, y_train_batch)\n",
    "            epoch_train_loss += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        mean_epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(mean_epoch_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_valid_loss = 0.\n",
    "        with torch.no_grad():\n",
    "            for X_valid_batch, y_valid_batch in valid_loader:\n",
    "                X_valid_batch, y_valid_batch = X_valid_batch.to(device), y_valid_batch.to(device)\n",
    "                y_valid_pred = model(X_valid_batch)\n",
    "                valid_loss = loss_fn(y_valid_pred, y_valid_batch)\n",
    "                epoch_valid_loss += valid_loss.item()\n",
    "        mean_epoch_valid_loss = epoch_valid_loss / len(valid_loader)\n",
    "        valid_losses.append(mean_epoch_valid_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Training Loss: {mean_epoch_train_loss:.4f}, Valid Loss: {mean_epoch_valid_loss:.4f}\")\n",
    "\n",
    "    return (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jsz9EXx84c2B",
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1741842471337,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "Jsz9EXx84c2B"
   },
   "outputs": [],
   "source": [
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tj-16iQY4ZhT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14881,
     "status": "ok",
     "timestamp": 1741843753067,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "tj-16iQY4ZhT",
    "outputId": "ddd6c3a9-52d7-4d41-de03-9e744e9a210c"
   },
   "outputs": [],
   "source": [
    "model = set_model().to(device)\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()\n",
    "n_epochs = 20\n",
    "train_losses, valid_losses = train_v4(model, optimizer, mse, train_loader, valid_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oxivxu1k-j2W",
   "metadata": {
    "id": "oxivxu1k-j2W"
   },
   "source": [
    "Do you notice anything strange with the learning curves?\n",
    "\n",
    "What could we do to fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HhBFX66yA_wc",
   "metadata": {
    "id": "HhBFX66yA_wc"
   },
   "source": [
    "### Evaluation metrics and classification\n",
    "\n",
    "Let's now train an image classifier and use evaluation metrics.  \n",
    "\n",
    "`torchvision` is the PyTorch module containing popular datasets, model architectures, and common image transformations for computer vision. We will just use it to load the Fashion MNIST dataset and do a few quick pre-processing today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfW7e9PyBS28",
   "metadata": {
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1741844720938,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "dfW7e9PyBS28"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drwptCA8DAvs",
   "metadata": {
    "id": "drwptCA8DAvs"
   },
   "source": [
    "The following instructions are used to:\n",
    "1. Define a pre-processing function to convert images to PyTorch `Image` datatype (subclass of `Tensor`), with float32 type and scaling of the pixel's values between 0 and 1 (from 0 to 255 in original images).\n",
    "2. Load the Fashion MNIST dataset (train and test sets) and apply the pre-processing.\n",
    "3. Split the trainig data in training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z7gU48wMB7Dz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6648,
     "status": "ok",
     "timestamp": 1741845129919,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "z7gU48wMB7Dz",
    "outputId": "ce1a5706-11d6-4caf-cca6-b7edd070c2e8"
   },
   "outputs": [],
   "source": [
    "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)]) # Define a pre-processing function to convert loaded images to adequate format\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(root=\"datasets\", train=True, download=True, transform=toTensor)\n",
    "test_data = torchvision.datasets.FashionMNIST(root=\"datasets\", train=False, download=True, transform=toTensor)\n",
    "train_data, valid_data = torch.utils.data.random_split(train_and_valid_data, [55_000, 5_000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eJEG5XI-Dw2k",
   "metadata": {
    "id": "eJEG5XI-Dw2k"
   },
   "source": [
    "Create the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tbNf2oHqDw-C",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741845131670,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "tbNf2oHqDw-C"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jTCSc9x9EHor",
   "metadata": {
    "id": "jTCSc9x9EHor"
   },
   "source": [
    "Look at the shape of the first image, its data type and the target class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BCeEzaJaD3gc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741845159003,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "BCeEzaJaD3gc",
    "outputId": "b94cefd9-3d71-43c9-d24e-d15cc74d9593"
   },
   "outputs": [],
   "source": [
    "X_sample, y_sample = train_data[0]\n",
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edncSlmSD_cU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741845181929,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "edncSlmSD_cU",
    "outputId": "8f473116-c63b-4fdc-bb23-c4a7d1e55cc7"
   },
   "outputs": [],
   "source": [
    "X_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hvZToxeZEDn1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741845184319,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "hvZToxeZEDn1",
    "outputId": "ef0c7148-0568-4358-f609-2f6aacfeace4"
   },
   "outputs": [],
   "source": [
    "train_and_valid_data.classes[y_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "npGWaXsIEYsT",
   "metadata": {
    "id": "npGWaXsIEYsT"
   },
   "source": [
    "You can find below a more structured way of declaring a model. This can give you more freedom in terms of architecture design.\n",
    "\n",
    "The code defines a class, inheriting from the `nn.Module` module, to instance models with 2 hidden layers and one output layer. The user can pass the number of inputs, neurons in hidden layer 1 and 2 and number of classes to instance models.\n",
    "\n",
    "The `forward` method has to be present if you use this approach, as this is automatically called when you use perform a forward pass through the model (i.e., `model(X)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cNw9wboWEWHz",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1741845614787,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "cNw9wboWEWHz"
   },
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
    "      super().__init__()\n",
    "      self.mlp = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(n_inputs, n_hidden1),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_hidden1, n_hidden2),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_hidden2, n_classes)\n",
    "      )\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YMYNtR75EYXT",
   "metadata": {
    "id": "YMYNtR75EYXT"
   },
   "source": [
    "Let's update our previous traninig loop to include the evaluation metric calculation and return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wJlbUeOIGIYz",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741847122183,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "wJlbUeOIGIYz"
   },
   "outputs": [],
   "source": [
    "def train_v5(model, optimizer, loss_fn, eval_metric, train_loader, valid_loader, n_epochs):\n",
    "    train_losses = []\n",
    "    train_eval_metrics = []\n",
    "    valid_losses = []\n",
    "    valid_eval_metrics= []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Model evaluation\n",
    "        model.eval()\n",
    "        eval_metric.reset() # Reset the eval metric\n",
    "        epoch_valid_loss = 0.\n",
    "        with torch.no_grad():\n",
    "            for X_valid_batch, y_valid_batch in valid_loader:\n",
    "                X_valid_batch, y_valid_batch = X_valid_batch.to(device), y_valid_batch.to(device)\n",
    "                y_valid_pred = model(X_valid_batch)\n",
    "                valid_loss = loss_fn(y_valid_pred, y_valid_batch)\n",
    "                epoch_valid_loss += valid_loss.item()  # Update eval metric for validation\n",
    "                eval_metric.update(y_valid_pred, y_valid_batch)\n",
    "        mean_epoch_valid_loss = epoch_valid_loss / len(valid_loader)\n",
    "        valid_losses.append(mean_epoch_valid_loss)\n",
    "        # Calculte and store validation eval metric for this epoch\n",
    "        epoch_valid_eval_metric = eval_metric.compute().item()\n",
    "        valid_eval_metrics.append(epoch_valid_eval_metric)\n",
    "\n",
    "        #Training\n",
    "        eval_metric.reset() # Reset the eval metric\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            y_train_pred = model(X_train_batch)\n",
    "            train_loss = loss_fn(y_train_pred, y_train_batch)\n",
    "            epoch_train_loss += train_loss.item()\n",
    "            train_loss.backward()\n",
    "            eval_metric.update(y_train_pred, y_train_batch) # Update eval metric for training\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        mean_epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(mean_epoch_train_loss)\n",
    "        # Calculte and store training eval metric for this epoch\n",
    "        epoch_training_eval_metric = eval_metric.compute().item()\n",
    "        train_eval_metrics.append(epoch_training_eval_metric)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Training Loss: {mean_epoch_train_loss:.4f}, Valid Loss: {mean_epoch_valid_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Training Eval Metric: {epoch_training_eval_metric:.4f}, Valid Eval Metric: {epoch_valid_eval_metric:.4f}\")\n",
    "\n",
    "    return (train_losses, valid_losses, train_eval_metrics, valid_eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662kIljBImkz",
   "metadata": {
    "id": "662kIljBImkz"
   },
   "source": [
    "Create an instance of the model and define the loss as Cross Entropy (loss for classification), the evaluation metric as accuracy, the optimiser as SGD (which works as mini-batch GD in our setup) and the number of epochs to 10.\n",
    "\n",
    "Move the model to the GPU and start the training (will take a few minutes on the Colab T4 GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mODE8Tg_Hv3j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160704,
     "status": "ok",
     "timestamp": 1741847287838,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "mODE8Tg_Hv3j",
    "outputId": "1f39e216-9baa-465f-c933-f37d48b8f870"
   },
   "outputs": [],
   "source": [
    "model = ImageClassifier(n_inputs=28 * 28, n_hidden1=300, n_hidden2=100, n_classes=10)\n",
    "xentropy = nn.CrossEntropyLoss()\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "n_epochs = 10\n",
    "\n",
    "model = model.to(device)\n",
    "train_losses, valid_losses, train_accuracy, valid_accuracy = train_v5(model, optimizer, xentropy, accuracy, train_loader, valid_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rWKARQ-uJjFc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1741847533819,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "rWKARQ-uJjFc",
    "outputId": "dccde575-a4a2-430c-8153-3c8bc1dc26d7"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses[1:], label='Training loss')\n",
    "plt.plot(valid_losses[1:], label='Validation loss')\n",
    "plt.plot(train_accuracy[1:], label='Training accuracy')\n",
    "plt.plot(valid_accuracy[1:], label='Validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RBfjvPwlNx07",
   "metadata": {
    "id": "RBfjvPwlNx07"
   },
   "source": [
    "You can now use the model to make predictions on \"new\" images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bFLF2G80NOTc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1741847687955,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "bFLF2G80NOTc",
    "outputId": "d5149c32-5494-4b64-ad46-4f202cb2fe4d"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "X_new, y_new = next(iter(valid_loader))\n",
    "X_new = X_new[:3].to(device)\n",
    "with torch.no_grad():\n",
    "  y_pred_logits = model(X_new)\n",
    "y_pred = y_pred_logits.argmax(axis=1) # index of the largest logit\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fSmyDhpWNShL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1741847605205,
     "user": {
      "displayName": "Thomas Lacombe",
      "userId": "06456522030533867615"
     },
     "user_tz": -780
    },
    "id": "fSmyDhpWNShL",
    "outputId": "24f9412a-daac-456d-8d85-32dcb6a55b3a"
   },
   "outputs": [],
   "source": [
    "[train_and_valid_data.classes[index] for index in y_pred]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cf53606c-e892-4321-bf19-f4364dac1275",
    "W-lDl2z6EzEl"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:COMPSCI714]",
   "language": "python",
   "name": "conda-env-COMPSCI714-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
